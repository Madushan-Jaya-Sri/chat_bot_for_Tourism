{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 23:19:01.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 23:19:01.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 23:19:01.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 23:19:01.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 23:19:01.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 23:19:01.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 23:19:01.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not openai_api_key:\n",
    "    st.error(\"API key is not found. Please set it in the .env file.\")\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Function to extract text, images, and tables from PDF\n",
    "def extract_data_from_pdf(pdf_file):\n",
    "    text = \"\"\n",
    "    tables = []\n",
    "    images = []\n",
    "\n",
    "    # Using pdfplumber for better text and table extraction\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "            tables.extend(page.extract_tables())\n",
    "            for i, image in enumerate(page.images):\n",
    "                # Convert the image to a PIL Image\n",
    "                img = page.to_image()\n",
    "                img_path = f\"images/page_{page.page_number}_img_{i}.png\"\n",
    "                img.save(img_path)\n",
    "                images.append(img_path)\n",
    "\n",
    "    return text, tables, images\n",
    "\n",
    "# Function to analyze and extract text from images\n",
    "def analyze_images(image_paths):\n",
    "    image_descriptions = []\n",
    "    for img_path in image_paths:\n",
    "        img = Image.open(img_path)\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        image_descriptions.append({\"path\": img_path, \"text\": text})\n",
    "    return image_descriptions\n",
    "\n",
    "# Function to create a vector store from extracted data\n",
    "def create_vector_store(text, tables, images):\n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_text(text)\n",
    "\n",
    "    # Create embeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "    # Create embeddings for tables and images\n",
    "    table_texts = [str(table) for table in tables]\n",
    "    table_embeddings = FAISS.from_texts(table_texts, embeddings)\n",
    "\n",
    "    image_texts = [desc['text'] for desc in images]\n",
    "    image_embeddings = FAISS.from_texts(image_texts, embeddings)\n",
    "\n",
    "    return vector_store, table_embeddings, image_embeddings\n",
    "\n",
    "# Function to query GPT-4\n",
    "def query_gpt4(query, context):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {query}\"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error querying GPT-4: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main function for the Streamlit app\n",
    "def main():\n",
    "    st.title(\"RAG System for Unstructured Data\")\n",
    "\n",
    "    uploaded_file = st.file_uploader(\"Choose a PDF file\", type=\"pdf\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        # Extract data from PDF\n",
    "        text, tables, images = extract_data_from_pdf(uploaded_file)\n",
    "\n",
    "        # Extracting image documents\n",
    "        image_docs = analyze_images(images)\n",
    "        print(image_docs)  # Ensure this returns a list of dictionaries\n",
    "\n",
    "        # Join the text from the dictionary objects\n",
    "        context_images = \"\\n\".join([desc['text'] for desc in image_docs]) \n",
    "\n",
    "        # Create vector store\n",
    "        vector_store, table_embeddings, image_embeddings = create_vector_store(text, tables, image_docs)\n",
    "\n",
    "        st.session_state['vector_store'] = vector_store\n",
    "        st.session_state['table_embeddings'] = table_embeddings\n",
    "        st.session_state['image_embeddings'] = image_embeddings\n",
    "        st.success(\"PDF processed successfully!\")\n",
    "\n",
    "        # Chat interface\n",
    "        query = st.text_input(\"Your question about the PDF:\")\n",
    "\n",
    "        if query:\n",
    "            # Retrieve relevant documents from text vector store\n",
    "            docs = vector_store.similarity_search(query, k=3)\n",
    "            context_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "            # Retrieve relevant tables\n",
    "            table_docs = table_embeddings.similarity_search(query, k=3)\n",
    "            context_tables = \"\\n\".join([str(doc) for doc in table_docs])\n",
    "\n",
    "            # Retrieve relevant images\n",
    "            image_docs = image_embeddings.similarity_search(query, k=3)\n",
    "            context_images = \"\\n\".join([desc['text'] for desc in image_docs])\n",
    "\n",
    "            # Compile all contexts\n",
    "            final_context = context_text + \"\\n\" + context_tables + \"\\n\" + context_images\n",
    "\n",
    "            # Query GPT-4\n",
    "            response = query_gpt4(query, final_context)\n",
    "            if response:\n",
    "                st.markdown(f\"**Answer:** {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
